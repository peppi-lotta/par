# Evaluation

## Source the necessary packages and functions

```{r}
install.packages("MCMCpack")
install.packages("dplyr")
install.packages("data.table")
install.packages("future")
install.packages("future.apply")
install.packages("furrr")
install.packages("compiler")
```


```{r}
library(MCMCpack)
library(dplyr)
library(data.table)
library(future)
library(future.apply)
library(furrr)
library(compiler)
```

```{r}
devtools::install_github("peppi-lotta/par")
library(par)
compile_all()
```

## Define the helper functions

```{r}
#' Get the values of a, b, c, and d for a given set of probabilities and N
#' 
#' @param p The probability of disease (D^+) given exposure (E^+)
#' p = P(D^+ |E^+)
#' @param q The probability of disease (D^+) given there is no exposure (E^-)
#' q = P(D^+ |E^-)
#' @param e The probability of exposure in total (E^+)
#' e = P(E^+)
#' @param n The number of observations
#' n = n
#' @return A list of values for a, b, c, and d
#' where:
#' a = p * e * n. The count of rows where both exposure and outcome are 1. 
#' b = ( 1 - p ) * e * n. The count of rows where exposure is 1 and outcome is 0.
#' c = q * ( 1 - e ) * n. The count of rows where exposure is 0 and outcome is 1.
#' d = ( 1 - q ) * ( 1 - e ) * n. The count of rows where both exposure and outcome are 0.
get_probabilities_2x2_table <- function( p, q, e ) {
  p_11 <- p * e
  p_10 <- ( 1 - p ) * e
  p_01 <- q * ( 1 - e )
  p_00 <- ( 1 - q ) * ( 1 - e )

  return(list(p_11 = p_11, p_10 = p_10, p_01 = p_01, p_00 = p_00))
}
```

## Calculate the coverage percentage

```{r}
# Set the interval and prior values
interval <- 0.95
prior <- c(1, 0.1, 1, 0.1)

# Create a data frame with all combinations of the values
combinations <- expand.grid(
  p = c(0.001, 0.01 , 0.05, 0.1 , 0.2 , 0.3 , 0.35, 0.4 , 0.45 , 0.5),
  q = c(0.001, 0.01 , 0.05, 0.1 , 0.2 , 0.3 , 0.35, 0.4 , 0.45 , 0.5),
  e = c(0.01 , 0.1  , 0.2 , 0.3 , 0.4 , 0.5 , 0.6 , 0.7 , 0.8  , 0.9),
  n = c(16, 64, 256, 1024)
)

combinations <- as.data.table(combinations)
total_combinations_count <- nrow(combinations)
# Initialize columns with NA values
combinations[, c(
    "p_11",
    "p_10",
    "p_01",
    "p_00",
    "actual_par",
    "bayes_ci_mean_length",
    "bayes_ci_coverage"
    ) := NA_real_
]

# Vectorized calculation of probabilities and actual_par
probabilities <- combinations[, get_probabilities_2x2_table(p, q, e), by = 1:total_combinations_count]
combinations[, actual_par := p * e + q * (1 - e) - q]

# Combine results into a data table
dt <- data.table(
  p = combinations$p,
  q = combinations$q,
  e = combinations$e,
  n = combinations$n,
  p_11 = probabilities$p_11,
  p_10 = probabilities$p_10,
  p_01 = probabilities$p_01,
  p_00 = probabilities$p_00,
  actual_par = combinations$actual_par,
  interval = interval,
  prior = paste(prior, collapse = ",")
)

# Write the data table to a CSV file
write.csv(dt, "combinations.csv")
```

```{r}
# Set the plan for parallel processing
plan(multisession)

# Specify the file path.
file_path <- "./combinations.csv"
data <- read.csv(file_path)
start <- 1
end <- 4000

# Initialize columns with NA values
data$bayes_ci_mean_length = NA_real_
data$bayes_ci_coverage = NA_real_
data$boot_ci_mean_length = NA_real_
data$boot_ci_coverage = NA_real_

# Record the start time
start_time <- Sys.time()
print(paste("Program start time:", start_time))

# Optimize main loop using future.apply
results <- future_map(start:end, function(i) {
  row <- data[i, ]
  # Simulate Bayesian CI
  samples <- rmultinom(1000, row$n, c(row$p_11, row$p_10, row$p_01, row$p_00))
  
  bayes_cis <- apply(samples, 2, function(sample) {
    a <- sample[1]
    b <- sample[2]
    c <- sample[3]
    d <- sample[4]
    n <- a + b + c + d
    calculate_bayesian_ci("par", c(a, b, c, d), interval, prior, 2000)
  })
  
  # Calculate metrics for Bayesian CI
  bayes_mean_length <- mean(bayes_cis[2, ] - bayes_cis[1, ])
  bayes_coverage <- mean(bayes_cis[1, ] <= row$actual_par & bayes_cis[2, ] >= row$actual_par)

  # Simulate Bootstrap CI
  boot_cis <- apply(samples, 2, function(sample) {
    a <- sample[1]
    b <- sample[2]
    c <- sample[3]
    d <- sample[4]
    n <- a + b + c + d
    calculate_bootstrap_ci("par", c(a, b, c, d), interval, 2000)
  })
  
  # Calculate metrics for Bootstrap CI
  boot_mean_length <- mean(boot_cis[2, ] - boot_cis[1, ])
  boot_coverage <- mean(boot_cis[1, ] <= row$actual_par & boot_cis[2, ] >= row$actual_par)
  
  # Return the results as a list
  list(
    p = row$p,
    q = row$q,
    e = row$e,
    n = row$n,
    p_11 = row$p_11,
    p_10 = row$p_10,
    p_01 = row$p_01,
    p_00 = row$p_00,
    actual_par = row$actual_par,
    interval = row$interval,
    prior = row$prior,
    bayes_ci_mean_length = bayes_mean_length,
    bayes_ci_coverage = bayes_coverage,
    boot_ci_mean_length = boot_mean_length,
    boot_ci_coverage = boot_coverage
  )
}, .options = furrr_options(seed = 123))

# Combine results into a data table
final_results <- rbindlist(results)

# Record the end time
end_time <- Sys.time()
print(paste("Program end time:", end_time))

# Write the final results to a CSV file
file_name <- paste0("data_prior_1-0.1-1-0.1.csv")
write.csv(final_results, file_name)
```

## Evaluation figures

```{r}
# Load necessary libraries
library(ggplot2)
library(dplyr)
library(tidyr)
library(readr)
library(GGally)

# Read the merged data
data <- read_csv(
  "./merged_data.csv",
  col_types = cols(
    prior = col_character(),
    V1 = col_double(),
    p = col_double(),
    q = col_double(),
    e = col_double(),
    n = col_double(),
    p_11 = col_double(),
    p_10 = col_double(),
    p_01 = col_double(),
    p_00 = col_double(),
    actual_par = col_double(),
    bayes_ci_mean_length = col_double(),
    bayes_ci_coverage = col_double(),
    boot_ci_mean_length = col_double(),
    boot_ci_coverage = col_double(),
    interval = col_double()
  )
)

# Convert 'prior' to factor for grouping
data$prior <- as.factor(data$prior)
```

```{r, fig.width=10, fig.height=8}
ggplot(data, aes(x = factor(n), y = bayes_ci_coverage, fill = "Bayesian")) +
  geom_boxplot(outlier.shape = NA, alpha = 0.4) +
  geom_boxplot(aes(y = boot_ci_coverage, fill = "Bootstrap"), outlier.shape = NA, alpha = 0.4) +
  geom_hline(yintercept = 0.95, linetype = "dashed", color = "darkgray") +
  facet_wrap(~prior) +
  scale_fill_manual(values = c("Bayesian" = "salmon", "Bootstrap" = "skyblue")) +
  labs(
    title = "Coverage Comparison of Confidence Intervals",
    x = "Sample Size (n)",
    y = "Coverage",
    fill = "Method"
  ) +
  theme_minimal()

ggplot(data, aes(x = factor(n), y = bayes_ci_mean_length, fill = "Bayesian")) +
  geom_boxplot(outlier.shape = NA, alpha = 0.4) +
  geom_boxplot(aes(y = boot_ci_mean_length, fill = "Bootstrap"), outlier.shape = NA, alpha = 0.4) +
  facet_wrap(~prior) +
  scale_fill_manual(values = c("Bayesian" = "salmon", "Bootstrap" = "skyblue")) +
  labs(
    title = "Mean Confidence Interval Length by Method",
    x = "Sample Size (n)",
    y = "Mean CI Length",
    fill = "Method"
  ) +
  theme_minimal()

data_summary <- data %>%
  group_by(n, prior) %>%
  summarise(
    bayes_better_cov = mean(abs(bayes_ci_coverage - 0.95) < abs(boot_ci_coverage - 0.95)),
    bayes_shorter = mean(bayes_ci_mean_length < boot_ci_mean_length),
    .groups = 'drop'
  )

# Optional: Scatterplot of Length vs Coverage for each method
ggplot(data, aes(x = bayes_ci_mean_length, y = bayes_ci_coverage)) +
  geom_point(color = "blue") +
  labs(
    title = "Bayesian CI: Length vs Coverage",
    x = "Mean Length",
    y = "Coverage"
  ) +
  theme_minimal()

ggplot(data, aes(x = boot_ci_mean_length, y = boot_ci_coverage)) +
  geom_point(color = "red") +
  labs(
    title = "Bootstrap CI: Length vs Coverage",
    x = "Mean Length",
    y = "Coverage"
  ) +
  theme_minimal()

data <- data %>%
  mutate(
    nominal = 0.95,
    bayes_closer = abs(bayes_ci_coverage - nominal) < abs(boot_ci_coverage - nominal),
    bayes_shorter = bayes_ci_mean_length < boot_ci_mean_length,
    group = paste("n =", n, "| prior =", prior)
  )


# Boxplot: Which method gives shorter intervals across groups
ggplot(data, aes(x = group, fill = bayes_shorter)) +
  geom_bar(position = "fill") +
  labs(
    title = "Proportion of Cases Where Bayesian Interval is Shorter",
    y = "Proportion",
    x = "Sample Size & Prior",
    fill = "Bayesian Shorter?"
  ) +
  coord_flip() +
  theme_minimal()

ggplot(data, aes(x = group, fill = bayes_closer)) +
  geom_bar(position = "fill") +
  labs(
    title = "Proportion Where Bayesian is Closer to Nominal Coverage",
    y = "Proportion",
    x = "Sample Size & Prior",
    fill = "Bayesian Closer?"
  ) +
  coord_flip() +
  theme_minimal()

summary_table <- data %>%
  group_by(prior, n) %>%
  summarise(
    bayes_better_coverage = mean(bayes_closer),
    bayes_shorter_interval = mean(bayes_shorter),
    .groups = 'drop'
  )

# Create a long format for easier plotting
coverage_long <- data %>%
  select(e, prior, bayes_ci_coverage, boot_ci_coverage) %>%
  pivot_longer(cols = c(bayes_ci_coverage, boot_ci_coverage),
               names_to = "method", values_to = "coverage") %>%
  mutate(method = recode(method,
                         bayes_ci_coverage = "Bayesian",
                         boot_ci_coverage = "Bootstrap"))

# Plot: Coverage vs. Effect Size (e) for both methods
ggplot(coverage_long, aes(x = e, y = coverage, color = method)) +
  geom_smooth(se = FALSE, size = 1.2) +
  geom_hline(yintercept = 0.95, linetype = "dashed", color = "gray40") +
  facet_wrap(~prior) +
  scale_color_manual(values = c("Bayesian" = "salmon", "Bootstrap" = "skyblue")) +
  labs(
    title = "Percent Coverage for all e",
    x = "Effect Size (e)",
    y = "Coverage",
    color = "Method"
  ) +
  theme_minimal(base_size = 16) +
  theme(
    plot.title = element_text(size = 18, face = "bold"),
    legend.position = "top"
  )

print(summary_table)
```
